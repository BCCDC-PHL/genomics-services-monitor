#!/usr/bin/env python3

import argparse
import csv
import datetime
import json
import os
import subprocess
import sys
import time


def parse_services_list(services_list_path):
    """
    Parse the services list file and return a list of services.

    If a service has an empty log path, the log path will be set to None.
    If a service has a log path that does not exist, the log path will be set to None.

    :param services_list_path: The path to the services list file
    :type services_list_path: str
    :return: The services list. Keys of services list are: ['service_name', 'log_path']
    :rtype: list
    """
    services = []
    maybe_empty_fields = ['log_path']
    path_fields = ['log_path']
    with open(services_list_path) as f:
        reader = csv.DictReader(f, dialect='unix')
        for row in reader:
            service = {}
            for k, v in row.items():
                if k in maybe_empty_fields and v == '':
                    v = None
                if k in path_fields and v is not None:
                    if not os.path.exists(v):
                        v = None
                    else:
                        v = os.path.abspath(v)
                service[k] = v
            services.append(service)

    return services


def check_service(service_name):
    """
    Use systemctl to check the status of a service and return the status as a dict.

    :param service_name: The name of the service to check
    :type service_name: str
    :return: The status of the service. Keys of the service status are:
             ['service_name', 'service_id', 'active_state', 'sub_state', 'timestamp_started', 'timestamp_checked', 'account']
    :rtype: dict
    """
    timestamp_checked = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    result = subprocess.run(["systemctl", "--user", "show", service_name], capture_output=True, text=True, check=True)
    output = result.stdout.split('\n')
    account = os.getlogin()
    service = {
        'timestamp_checked': timestamp_checked,
        'account': account
    }
    collected_keys_lookup = {
        'Id': 'service_id',
        'ActiveState': 'active_state',
        'SubState': 'sub_state',
        'ExecMainStartTimestamp': 'timestamp_started',
    }
    keys_to_collect = set(collected_keys_lookup.keys())
    for entry in output:
        kv = entry.split("=", 1)
        if len(kv) == 2:
            k, v = kv
            if k in keys_to_collect:
                if k == 'ExecMainStartTimestamp':
                    v = ' '.join(v.split(' ')[1:3])

                service[collected_keys_lookup[k]] = v

    service['service_name'] = service['service_id'].removesuffix('.service')

    return service


def parse_service_status(service_status_path):
    """
    Parse the service status file and return a list of service statuses
    """
    service_status = []
    with open(service_status_path, 'r') as f:
        try:
            service_status = json.load(f)
        except Exception as e:
            pass

    return service_status


def update_service_status(previous_service_status, current_service_status):
    """
    """
    keys_to_update = [
        'active_state',
        'sub_state',
        'timestamp_started',
        'timestamp_checked',
    ]
    for k in keys_to_update:
        if k in current_service_status:
            previous_service_status[k] = current_service_status[k]

    if current_service_status['active_state'] == 'active':
        previous_service_status['timestamp_last_active'] = current_service_status['timestamp_checked']

    return previous_service_status.copy()


def main(args):
    if not os.path.exists(args.service_status_outdir):
        os.makedirs(args.service_status_outdir, exist_ok=True)

    while True:
        try:
            services = parse_services_list(args.services_list)

            if args.service_status_prefix is None:
                service_status_json_path = os.path.join(args.service_status_outdir, f"services.json")
            else:
                service_status_json_path = os.path.join(args.service_status_outdir, f"{args.service_status_prefix}_services.json")

            if not os.path.exists(service_status_json_path):
                with open(service_status_json_path, 'w') as f:
                    f.write('[]\n')

            current_service_statuses = []
            current_service_logs_by_service_name = {}
            for service in services:
                service_name = service.get('service_name', None)
                if not service_name:
                    print(json.dumps({
                        "timestamp": datetime.datetime.now().isoformat(),
                        "message": {
                            "event_type": "service_skipped",
                            "reason": "failed to determine service name",
                        }
                    })) 
                    continue

                current_service_status = check_service(service_name)
                previous_service_statuses = parse_service_status(service_status_json_path)
                for previous_service_status in previous_service_statuses:
                    if current_service_status['service_id'] == previous_service_status['service_id']:
                        current_service_status = update_service_status(previous_service_status, current_service_status)
                current_service_statuses.append(current_service_status)

                if service['log_path'] is not None:
                    # Take the last 100 lines of the log file
                    service_log_lines = []
                    try:
                        print(json.dumps({
                            "timestamp": datetime.datetime.now().isoformat(),
                            "message": {
                                "event_type": "log_collection_started",
                                "service_name": service_name,
                            }
                        }))
                        result = subprocess.run(["tail", "-n", "100", service['log_path']], capture_output=True, text=True, check=True)
                        service_log_lines = result.stdout.split('\n')
                    except subprocess.CalledProcessError as e:
                        print(json.dumps({
                            "timestamp": datetime.datetime.now().isoformat(),
                            "message": {
                                "event_type": "failed_to_collect_logs",
                                "service_name": service_name,
                            }
                        }))
                        current_service_logs_by_service_name[service_name] = []

                    parsed_service_log_lines = []
                    for log_line in service_log_lines:
                        if not log_line:
                            continue
                        try:
                            # Note: we should fix these in the service logging formatters
                            log_line = log_line.replace("\"module\",", "\"module\":")
                            log_line = log_line.replace("\"line_num\",", "\"line_num\":")
                            parsed_line = json.loads(log_line)
                        except Exception as e:
                            print(json.dumps({
                                "timestamp": datetime.datetime.now().isoformat(),
                                "message": {
                                    "event_type": "log_line_parsing_failed",
                                    "service_name": service_name,
                                    "error": str(e),
                                }
                            }))
                            print(log_line)
                            continue
                        parsed_service_log_lines.append(parsed_line)
                    current_service_logs_by_service_name[service_name] = parsed_service_log_lines

            with open(service_status_json_path, 'w') as f:
                json.dump(current_service_statuses, f, indent=2)

            next_scan_timestamp = datetime.datetime.now() + datetime.timedelta(seconds=args.scan_interval_seconds)
            print(json.dumps({
                "timestamp": datetime.datetime.now().isoformat(),
                "message": {
                    "event_type": "service_status_updated",
                    "services_checked": [service['service_name'] for service in services],
                    "timestamp_next_scan_start": next_scan_timestamp.isoformat(),
                }
            }))

            for service_name, log_lines in current_service_logs_by_service_name.items():
                if not os.path.exists(os.path.join(args.service_status_outdir, 'logs', args.service_status_prefix)):
                    os.makedirs(os.path.join(args.service_status_outdir, 'logs', args.service_status_prefix), exist_ok=True)
                log_json_output_path = os.path.join(args.service_status_outdir, 'logs', args.service_status_prefix, f"{service_name}_log.json")

                with open(log_json_output_path, 'w') as f:
                    json.dump(log_lines, f, indent=2)

            time.sleep(args.scan_interval_seconds)
        except KeyboardInterrupt as e:
            timestamp_checked = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            for service_status in previous_service_statuses:
                if service_status['service_id'] == 'genomics-services-monitor.service':
                   service_status['active_state'] = 'inactive'
                   service_status['timestamp_checked'] = timestamp_checked
            
            with open(service_status_json_path, 'w') as f:
                json.dump(previous_service_statuses, f, indent=2)

            exit(-1)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--services-list')
    parser.add_argument('--service-status-outdir')
    parser.add_argument('--service-status-prefix')
    parser.add_argument('--scan-interval-seconds', type=int, default=60)
    args = parser.parse_args()
    main(args)
